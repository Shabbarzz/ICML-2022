{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-28T00:18:57.377929Z","iopub.execute_input":"2022-01-28T00:18:57.378289Z","iopub.status.idle":"2022-01-28T00:18:57.412467Z","shell.execute_reply.started":"2022-01-28T00:18:57.378190Z","shell.execute_reply":"2022-01-28T00:18:57.411536Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install monai tqdm\n!python -c \"import monai\" || pip install -q \"monai-weekly[nibabel, tqdm]\"\n!python -c \"import matplotlib\" || pip install -q matplotlib\n!pip install self-attention-cv==1.2.3\n%matplotlib inline\n\nimport os\nimport shutil\nimport tempfile\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom monai.apps import DecathlonDataset\nfrom monai.config import print_config\nfrom monai.data import DataLoader\nfrom monai.losses import DiceLoss, DiceCELoss\nfrom monai.metrics import DiceMetric\nfrom monai.networks.nets import UNet\nfrom monai.transforms import (\n    Activations,\n    AsChannelFirstd,\n    AsDiscrete,\n    CenterSpatialCropd,\n    Compose,\n    LoadImaged,\n    MapTransform,\n    NormalizeIntensityd,\n    Orientationd,\n    RandFlipd,\n    RandScaleIntensityd,\n    RandShiftIntensityd,\n    RandSpatialCropd,\n    Spacingd,\n    ToTensord,\n)\nfrom monai.utils import set_determinism\n\nimport torch\n\nprint_config()","metadata":{"execution":{"iopub.status.busy":"2022-01-28T00:19:04.654527Z","iopub.execute_input":"2022-01-28T00:19:04.655008Z","iopub.status.idle":"2022-01-28T00:19:18.515110Z","shell.execute_reply.started":"2022-01-28T00:19:04.654959Z","shell.execute_reply":"2022-01-28T00:19:18.513945Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"root_dir = './' \nprint(root_dir)\nset_determinism(seed=0)\n\nclass ConvertToMultiChannelBasedOnBratsClassesd(MapTransform):\n    \"\"\"\n    Convert labels to multi channels based on brats classes:\n    label 1 is the peritumoral edema\n    label 2 is the GD-enhancing tumor\n    label 3 is the necrotic and non-enhancing tumor core\n    The possible classes are TC (Tumor core), WT (Whole tumor)\n    and ET (Enhancing tumor).\n\n    \"\"\"\n\n    def __call__(self, data):\n        d = dict(data)\n        for key in self.keys:\n            result = []\n            # merge label 2 and label 3 to construct TC\n            result.append(np.logical_or(d[key] == 2, d[key] == 3))\n            # merge labels 1, 2 and 3 to construct WT\n            result.append(\n                np.logical_or(\n                    np.logical_or(d[key] == 2, d[key] == 3), d[key] == 1\n                )\n            )\n            # label 2 is ET\n            result.append(d[key] == 2)\n            d[key] = np.stack(result, axis=0).astype(np.float32)\n        return d","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roi_size=[128, 128, 64]\npixdim=(1.5, 1.5, 2.0)\n\ntrain_transform = Compose(\n    [\n        # load 4 Nifti images and stack them together\n        LoadImaged(keys=[\"image\", \"label\"]),\n        AsChannelFirstd(keys=\"image\"),\n        ConvertToMultiChannelBasedOnBratsClassesd(keys=\"label\"),\n        Spacingd(\n            keys=[\"image\", \"label\"],\n            pixdim=pixdim,\n            mode=(\"bilinear\", \"nearest\"),\n        ),\n        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n        RandSpatialCropd(\n            keys=[\"image\", \"label\"], roi_size=roi_size, random_size=False),\n        RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=0),\n        NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n        RandScaleIntensityd(keys=\"image\", factors=0.1, prob=0.5),\n        RandShiftIntensityd(keys=\"image\", offsets=0.1, prob=0.5),\n        ToTensord(keys=[\"image\", \"label\"]),\n    ]\n)\nval_transform = Compose(\n    [\n        LoadImaged(keys=[\"image\", \"label\"]),\n        AsChannelFirstd(keys=\"image\"),\n        ConvertToMultiChannelBasedOnBratsClassesd(keys=\"label\"),\n        Spacingd(\n            keys=[\"image\", \"label\"],\n            pixdim=pixdim,\n            mode=(\"bilinear\", \"nearest\"),\n        ),\n        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n        CenterSpatialCropd(keys=[\"image\", \"label\"], roi_size=roi_size),\n        NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n        ToTensord(keys=[\"image\", \"label\"]),\n    ]\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q \"monai-weekly[nibabel, tqdm]\"\ncache_num = 8\n\ntrain_ds = DecathlonDataset(\n    root_dir=root_dir,\n    task=\"Task01_BrainTumour\",\n    transform=train_transform,\n    section=\"training\",\n    download=True,\n    num_workers=4,\n    cache_num=cache_num, # it was 100 but we use larger volumes\n)\ntrain_loader = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=2)\nval_ds = DecathlonDataset(\n    root_dir=root_dir,\n    task=\"Task01_BrainTumour\",\n    transform=val_transform,\n    section=\"validation\",\n    download=False,\n    num_workers=4,\n    cache_num=cache_num,\n)\nval_loader = DataLoader(val_ds, batch_size=2, shuffle=False, num_workers=2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"slice_id = 32\n# pick one image from DecathlonDataset to visualize and check the 4 channels\nprint(f\"image shape: {val_ds[2]['image'].shape}\")\nplt.figure(\"image\", (24, 6))\nfor i in range(4):\n    plt.subplot(1, 4, i + 1)\n    plt.title(f\"image channel {i}\")\n    plt.imshow(val_ds[2][\"image\"][i, :, :, slice_id].detach().cpu(),  cmap=\"gray\") #\nplt.show()\n# also visualize the 3 channels label corresponding to this image\nprint(f\"label shape: {val_ds[2]['label'].shape}\")\nplt.figure(\"label\", (24, 6))\nfor i in range(3):\n    plt.subplot(1, 3, i + 1)\n    plt.title(f\"label channel {i}\")\n    plt.imshow(val_ds[6][\"label\"][i, :, :, slice_id].detach().cpu())\nplt.show()\n\ntrain_size = tuple(val_ds[6]['image'].shape[1:])\nprint(train_size)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from monai.networks.nets import UNETR as UNETR_monai\n\nfrom self_attention_cv import UNETR\ndevice = torch.device(\"cuda:0\")\nnum_heads = 10 # 12 normally \nembed_dim= 512 # 768 normally\n\n\n# model = UNETR(img_shape=tuple(roi_size), input_dim=4, output_dim=3,\n#                  embed_dim=embed_dim, patch_size=16, num_heads=num_heads,\n#                ext_layers=[3, 6, 9, 12], norm='instance',\n#                  base_filters=16,\n#                  dim_linear_block=2048).to(device)\n\nmodel = UNet(\n    dimensions=3,\n    in_channels=4,\n    out_channels=3,\n    channels=(16, 32, 64, 128, 256),\n    strides=(2, 2, 2, 2),\n    num_res_units=2,\n).to(device)\n\n# model = UNETR_monai(\n#     in_channels=4,\n#     out_channels=3,\n#     img_size=tuple(roi_size),\n#     feature_size=16,\n#     hidden_size=embed_dim,\n#     mlp_dim=3072,\n#     num_heads=12,\n#     pos_embed=\"perceptron\",\n#     norm_name=\"instance\",\n#     res_block=True,\n#     dropout_rate=0.0,\n# ).to(device)\n\npytorch_total_params = sum(p.numel() for p in model.parameters())/1000000\nprint('Parameters in millions:',pytorch_total_params)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nfrom monai.losses import DiceLoss, DiceCELoss\n\nloss_function = DiceCELoss(to_onehot_y=False, sigmoid=True)\n\n\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n\nmax_epochs = 180\nval_interval = 5\nbest_metric = -1\nbest_metric_epoch = -1\nepoch_loss_values = []\nmetric_values = []\nmetric_values_tc = []\nmetric_values_wt = []\nmetric_values_et = []\n\ntorch.cuda.empty_cache()\n\nfor epoch in range(max_epochs):\n    print(\"-\" * 10)\n    print(f\"epoch {epoch + 1}/{max_epochs}\")\n    model.train()\n    epoch_loss = 0\n    step = 0\n    for batch_data in train_loader:\n        step += 1\n        inputs, labels = (\n            batch_data[\"image\"].to(device),\n            batch_data[\"label\"].to(device),\n        )\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        \n        loss = loss_function(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        epoch_loss += loss.item()\n\n    epoch_loss /= step\n    epoch_loss_values.append(epoch_loss)\n    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n\n    if (epoch + 1) % val_interval == 0:\n        model.eval()\n        with torch.no_grad():\n            dice_metric = DiceMetric(include_background=True, reduction=\"mean\")\n            post_trans = Compose(\n                [Activations(sigmoid=True), AsDiscrete(threshold_values=True)]\n            )\n            metric_sum = metric_sum_tc = metric_sum_wt = metric_sum_et = 0.0\n            metric_count = (\n                metric_count_tc\n            ) = metric_count_wt = metric_count_et = 0\n            for val_data in val_loader:\n                val_inputs, val_labels = (\n                    val_data[\"image\"].to(device),\n                    val_data[\"label\"].to(device),\n                )\n                val_outputs = model(val_inputs)\n                val_outputs = post_trans(val_outputs)\n\n                # compute overall mean dice\n                value, not_nans = dice_metric(y_pred=val_outputs, y=val_labels)\n                not_nans = not_nans.mean().item()\n                metric_count += not_nans\n                metric_sum += value.mean().item() * not_nans\n                # compute mean dice for TC\n                value_tc, not_nans = dice_metric(\n                    y_pred=val_outputs[:, 0:1], y=val_labels[:, 0:1]\n                )\n                not_nans = not_nans.item()\n                metric_count_tc += not_nans\n                metric_sum_tc += value_tc.item() * not_nans\n                # compute mean dice for WT\n                value_wt, not_nans = dice_metric(\n                    y_pred=val_outputs[:, 1:2], y=val_labels[:, 1:2]\n                )\n                not_nans = not_nans.item()\n                metric_count_wt += not_nans\n                metric_sum_wt += value_wt.item() * not_nans\n                # compute mean dice for ET\n                value_et, not_nans = dice_metric(\n                    y_pred=val_outputs[:, 2:3], y=val_labels[:, 2:3]\n                )\n                not_nans = not_nans.item()\n                metric_count_et += not_nans\n                metric_sum_et += value_et.item() * not_nans\n\n            metric = metric_sum / metric_count\n            metric_values.append(metric)\n            metric_tc = metric_sum_tc / metric_count_tc\n            metric_values_tc.append(metric_tc)\n            metric_wt = metric_sum_wt / metric_count_wt\n            metric_values_wt.append(metric_wt)\n            metric_et = metric_sum_et / metric_count_et\n            metric_values_et.append(metric_et)\n            if metric > best_metric:\n                best_metric = metric\n                best_metric_epoch = epoch + 1\n                torch.save(\n                    model.state_dict(),\n                    os.path.join(root_dir, \"best_metric_model.pth\"),\n                )\n                print(\"saved new best metric model\")\n            print(\n                f\"current epoch: {epoch + 1} current mean dice: {metric:.4f}\"\n                f\" tc: {metric_tc:.4f} wt: {metric_wt:.4f} et: {metric_et:.4f}\"\n                f\"\\nbest mean dice: {best_metric:.4f}\"\n                f\" at epoch: {best_metric_epoch}\"\n            )\n\nsave_name = \"./last.pth\"\ntorch.save(model.state_dict(),save_name)\nfrom google.colab import files\nfiles.download(save_name)\n\nprint(\n    f\"train completed, best_metric: {best_metric:.4f}\"\n    f\" at epoch: {best_metric_epoch}\"\n)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# unet tutorial result: train completed, best_metric: 0.7537  at epoch: 160 # official tutorial\n# train completed, best_metric: 0.7660 at epoch: 170 # my run\n\n# self-attention-cv implementation of unetr\n# current epoch: 180 current mean dice: 0.7686 tc: 0.8116 wt: 0.8935 et: 0.6065\n# best mean dice: 0.7686 at epoch: 180\n\n# reduced version 50m params\ncurrent epoch: 180 current mean dice: 0.7693 tc: 0.8161 wt: 0.8922 et: 0.6057\nbest mean dice: 0.7693 at epoch: 180\n\n# unetr monai implementation\n# current epoch: 175 current mean dice: 0.7612 tc: 0.8122 wt: 0.8790 et: 0.5982 ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(\"train\", (12, 6))\nplt.subplot(1, 2, 1)\nplt.title(\"Epoch Average Loss\")\nx = [i + 1 for i in range(len(epoch_loss_values))]\ny = epoch_loss_values\nplt.xlabel(\"epoch\")\nplt.plot(x, y, color=\"red\")\nplt.subplot(1, 2, 2)\nplt.title(\"Val Mean Dice\")\nx = [val_interval * (i + 1) for i in range(len(metric_values))]\ny = metric_values\nplt.xlabel(\"epoch\")\nplt.plot(x, y, color=\"green\")\nplt.show()\n\nplt.figure(\"train\", (18, 6))\nplt.subplot(1, 3, 1)\nplt.title(\"Val Mean Dice TC\")\nx = [val_interval * (i + 1) for i in range(len(metric_values_tc))]\ny = metric_values_tc\nplt.xlabel(\"epoch\")\nplt.plot(x, y, color=\"blue\")\nplt.subplot(1, 3, 2)\nplt.title(\"Val Mean Dice WT\")\nx = [val_interval * (i + 1) for i in range(len(metric_values_wt))]\ny = metric_values_wt\nplt.xlabel(\"epoch\")\nplt.plot(x, y, color=\"brown\")\nplt.subplot(1, 3, 3)\nplt.title(\"Val Mean Dice ET\")\nx = [val_interval * (i + 1) for i in range(len(metric_values_et))]\ny = metric_values_et\nplt.xlabel(\"epoch\")\nplt.plot(x, y, color=\"purple\")\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_state_dict(\n    torch.load(os.path.join(root_dir, \"best_metric_model.pth\"))\n)\nmodel.eval()\nwith torch.no_grad():\n    # select one image to evaluate and visualize the model output\n    val_input = val_ds[6][\"image\"].unsqueeze(0).to(device)\n    val_output = model(val_input)\n    plt.figure(\"image\", (24, 6))\n    for i in range(4):\n        plt.subplot(1, 4, i + 1)\n        plt.title(f\"image channel {i}\")\n        plt.imshow(val_ds[6][\"image\"][i, :, :, 20].detach().cpu(), cmap=\"gray\")\n    plt.show()\n    # visualize the 3 channels label corresponding to this image\n    plt.figure(\"label\", (18, 6))\n    for i in range(3):\n        plt.subplot(1, 3, i + 1)\n        plt.title(f\"label channel {i}\")\n        plt.imshow(val_ds[6][\"label\"][i, :, :, 20].detach().cpu())\n    plt.show()\n    # visualize the 3 channels model output corresponding to this image\n    plt.figure(\"output\", (18, 6))\n    for i in range(3):\n        plt.subplot(1, 3, i + 1)\n        plt.title(f\"output channel {i}\")\n        out_tensor = torch.sigmoid(val_output[0, i, :, :, 20]).detach().cpu()\n        plt.imshow(out_tensor)\n    plt.show()","metadata":{},"execution_count":null,"outputs":[]}]}